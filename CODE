package com.spoka.english;

import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.content.res.Configuration;
import android.graphics.Color;
import android.graphics.Typeface;
import android.media.MediaPlayer;
import android.media.MediaRecorder;
import android.net.ConnectivityManager;
import android.net.NetworkInfo;
import android.os.Bundle;
import android.os.Environment;
import android.os.Handler;
import android.speech.tts.TextToSpeech;
import android.speech.tts.UtteranceProgressListener;
import android.speech.tts.Voice;
import android.text.Spannable;
import android.text.SpannableString;
import android.text.style.BackgroundColorSpan;
import android.text.style.ForegroundColorSpan;
import android.util.Log;
import android.view.Gravity;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.ImageButton;
import android.widget.LinearLayout;
import android.widget.ScrollView;
import android.widget.Spinner;
import android.widget.TextView;
import android.widget.ArrayAdapter;
import android.widget.AdapterView;
import android.app.AlertDialog;
import android.content.BroadcastReceiver;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Set;

import android.view.Gravity;
import android.widget.LinearLayout;
import com.google.android.material.floatingactionbutton.FloatingActionButton;

public class ConversationRecordingFragment extends Fragment {

    private static final String ARG_SELECTED_TITLE = "selectedTitle";
    private static final String ARG_ACTIVITY_TYPE = "activityType";
    private static final String UTTERANCE_ID = "ttsUtterance";
    private static final String RECORDING_UTTERANCE_ID = "recordingTtsUtterance";

    private static final String US_MALE = "en-us-x-iom";
    private static final String US_FEMALE = "en-us-x-tpc";
    private static final String UK_MALE = "en-gb-x-gbb";
    private static final String UK_FEMALE = "en-gb-x-gba";
    private static final String AUS_MALE = "en-au-x-aub";
    private static final String AUS_FEMALE = "en-au-x-auc";
    private static final String IN_MALE = "en-in-x-ene";
    private static final String IN_FEMALE = "en-in-x-enc";

    private LinearLayout passageContainer;
    private TextView statusText;
    private ImageButton playButton, pauseButton, voiceSelectionButton;
    private Spinner speedSelector;
    private ScrollView scrollView;
    private TextToSpeech tts;
    private Handler handler = new Handler();
    private int currentIndex = 0;

    private List<String> passageTitles = new ArrayList<>();
    private List<String> passages = new ArrayList<>();
    private List<Sentence> sentences = new ArrayList<>();
    private int currentSentenceIndex = 0;
    private boolean shouldContinuePlayback = false;
    private boolean isSpeaking = false;
    private long lastUtteranceDuration = 0;
    private long sentenceStartTime = 0;
    private boolean isFragmentVisible = false;
    private boolean isFragmentDestroyed = false;

    private String selectedTitle;
    private String activityType;
    private String currentLanguage = "US-English";

    private boolean voiceAvailable = false;
    private boolean voicesLoaded = false;
    private boolean loadingVoices = false;

    private int colorPersonA;
    private int colorPersonB;

    // Recording variables
    private MediaRecorder mediaRecorder;
    private Map<Integer, String> recordingFiles = new HashMap<>();
    private Map<Integer, MediaPlayer> mediaPlayers = new HashMap<>();
    private Map<Integer, ImageButton> recordingMicButtons = new HashMap<>();
    private Map<Integer, ImageButton> recordingStopButtons = new HashMap<>();
    private int currentlyPlayingRecording = -1;
    private boolean isRecording = false;
    private boolean isPlayingRecording = false;
    private boolean isPlayingTTSForRecording = false;
    private boolean isLessonCompleted = false;

    // Animation handler for blinking mic
    private Handler blinkHandler = new Handler();
    private Runnable blinkRunnable;

    // Floating download button
    private FloatingActionButton downloadFab;

    private class Sentence {
        String text;
        boolean isPersonA;
        String cleanText;
        int index;
        TextView textView;
        ImageButton micButton;
        ImageButton stopButton;

        public Sentence(String text, boolean isPersonA, int index) {
            this.text = text;
            this.isPersonA = isPersonA;
            this.cleanText = text.replaceFirst("^Person [AB]:\\s*", "");
            this.index = index;
        }
    }

    private BroadcastReceiver networkChangeReceiver = new BroadcastReceiver() {
        @Override
        public void onReceive(Context context, Intent intent) {
            if (!isAdded() || isFragmentDestroyed) return;
            if (!isNetworkAvailable()) {
                showNoInternetDialog();
            }
        }
    };

    public static ConversationRecordingFragment newInstance(String selectedTitle, String activityType) {
        ConversationRecordingFragment fragment = new ConversationRecordingFragment();
        Bundle args = new Bundle();
        args.putString(ARG_SELECTED_TITLE, selectedTitle);
        args.putString(ARG_ACTIVITY_TYPE, activityType);
        fragment.setArguments(args);
        return fragment;
    }

    @Override
    public void onCreate(@Nullable Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        if (getArguments() != null) {
            selectedTitle = getArguments().getString(ARG_SELECTED_TITLE);
            activityType = getArguments().getString(ARG_ACTIVITY_TYPE);
            colorPersonA = Color.parseColor("#2196F3");
            colorPersonB = Color.parseColor("#4CAF50");
        }
        initializeTts();
    }

    @Override
    public void onResume() {
        super.onResume();
        isFragmentVisible = true;
        resetAudio();
    }

    @Override
    public void onPause() {
        super.onPause();
        isFragmentVisible = false;
        pauseAudio();
        stopRecording();
        stopAllRecordingsPlayback();
        stopBlinking();
    }

    private void initializeTts() {
        if (tts != null || !isAdded() || getContext() == null || isFragmentDestroyed) return;

        tts = new TextToSpeech(getContext(), status -> {
            if (!isAdded() || getContext() == null || isFragmentDestroyed) {
                if (tts != null) {
                    tts.shutdown();
                }
                return;
            }

            if (status == TextToSpeech.SUCCESS) {
                setLanguageForCurrentSelection();

                tts.setOnUtteranceProgressListener(new UtteranceProgressListener() {
                    @Override
                    public void onStart(String utteranceId) {
                        handler.post(() -> {
                            if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                            if (!isFragmentVisible) {
                                if (tts != null) tts.stop();
                                return;
                            }

                            if (UTTERANCE_ID.equals(utteranceId)) {
                                // Normal TTS playback
                                isSpeaking = true;
                                sentenceStartTime = System.currentTimeMillis();
                                playButton.setVisibility(View.GONE);
                                pauseButton.setVisibility(View.VISIBLE);
                                setStatusText("\uD83D\uDD0A Listen Carefully...");
                                scrollToCurrentSentence();
                            } else if (RECORDING_UTTERANCE_ID.equals(utteranceId)) {
                                // TTS for recording playback
                                isPlayingTTSForRecording = true;
                                setStatusText("Playing example...");
                            }
                        });
                    }

                    @Override
                    public void onDone(String utteranceId) {
                        handler.post(() -> {
                            if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                            if (!isFragmentVisible) return;

                            if (UTTERANCE_ID.equals(utteranceId)) {
                                // Normal TTS playback done
                                lastUtteranceDuration = System.currentTimeMillis() - sentenceStartTime;

                                if (shouldContinuePlayback && !isLessonCompleted) {
                                    setStatusText("\uD83D\uDDE3\uFE0F Repeat what you heard...");

                                    // Start recording after TTS finishes
                                    startRecording();

                                    handler.postDelayed(() -> {
                                        if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                                        if (!isFragmentVisible) return;

                                        // Stop recording and prepare for next sentence
                                        stopRecording();

                                        if (shouldContinuePlayback && !isLessonCompleted) {
                                            if (currentSentenceIndex < sentences.size() - 1) {
                                                currentSentenceIndex++;
                                                highlightCurrentSentence();
                                                updateRecordingButtons();
                                                speakCurrentSentence();
                                            } else {
                                                // Lesson completed
                                                isLessonCompleted = true;
                                                shouldContinuePlayback = false;
                                                isSpeaking = false;
                                                playButton.setVisibility(View.VISIBLE);
                                                pauseButton.setVisibility(View.GONE);
                                                setStatusText("Lesson Completed!");
                                                Toast.makeText(getContext(), "Lesson completed successfully!", Toast.LENGTH_SHORT).show();

                                                // Show download button
                                                if (downloadFab != null) {
                                                    downloadFab.setVisibility(View.VISIBLE);
                                                }
                                            }
                                        }
                                    }, lastUtteranceDuration);
                                } else {
                                    isSpeaking = false;
                                    playButton.setVisibility(View.VISIBLE);
                                    pauseButton.setVisibility(View.GONE);
                                    setStatusText("Ready");
                                }
                            } else if (RECORDING_UTTERANCE_ID.equals(utteranceId)) {
                                // TTS for recording playback done - now play user recording
                                isPlayingTTSForRecording = false;
                                playUserRecording(currentlyPlayingRecording);
                            }
                        });
                    }

                    @Override
                    public void onError(String utteranceId) {
                        handler.post(() -> {
                            if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                            if (UTTERANCE_ID.equals(utteranceId)) {
                                isSpeaking = false;
                                playButton.setVisibility(View.VISIBLE);
                                pauseButton.setVisibility(View.GONE);
                                setStatusText("Error occurred");
                            } else if (RECORDING_UTTERANCE_ID.equals(utteranceId)) {
                                isPlayingTTSForRecording = false;
                                setStatusText("Error playing example");
                            }
                        });
                    }
                });

                loadAvailableVoices();
            } else {
                Log.e("TTS", "Initialization failed");
                showErrorDialog("Text-to-speech initialization failed");
            }
        }, "com.google.android.tts");
    }

    private void setLanguageForCurrentSelection() {
        Locale locale = Locale.US;
        switch (currentLanguage) {
            case "UK-English":
                locale = Locale.UK;
                break;
            case "AUS-English":
                locale = new Locale("en", "AU");
                break;
            case "IN-English":
                locale = new Locale("en", "IN");
                break;
        }
        int result = tts.setLanguage(locale);
        if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
            Log.e("TTS", "Language not supported");
        }
    }

    private void scrollToCurrentSentence() {
        if (passageContainer == null || sentences.isEmpty() || currentSentenceIndex >= sentences.size()) {
            return;
        }

        // Scroll to the current sentence
        View sentenceView = passageContainer.getChildAt(currentSentenceIndex);
        if (sentenceView != null) {
            int[] location = new int[2];
            sentenceView.getLocationOnScreen(location);
            int y = location[1];

            int scrollViewHeight = scrollView.getHeight();
            int desiredY = y - (scrollViewHeight / 3);

            scrollView.smoothScrollTo(0, Math.max(0, desiredY));
        }
    }

    private void setStatusText(String text) {
        if (statusText != null) {
            statusText.setText(text);
        }
    }

    private void loadAvailableVoices() {
        if (loadingVoices || !isAdded() || isFragmentDestroyed) return;

        loadingVoices = true;
        voiceAvailable = false;

        new Thread(() -> {
            int retries = 0;
            while (tts != null && tts.getVoices() == null && retries < 5 && !isFragmentDestroyed) {
                try {
                    Thread.sleep(200);
                    retries++;
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    return;
                }
            }

            if (!isAdded() || isFragmentDestroyed) {
                loadingVoices = false;
                return;
            }

            requireActivity().runOnUiThread(() -> {
                if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                voiceAvailable = setDefaultVoice();
                voicesLoaded = true;
                loadingVoices = false;

                if (voiceAvailable) {
                    Log.d("TTS", "Voices loaded successfully");
                    if (passages.size() > currentIndex) {
                        playButton.setEnabled(true);
                    }
                } else {
                    Log.d("TTS", "No voices available");
                    showVoiceNotAvailableToast();
                    playButton.setEnabled(false);
                }
            });
        }).start();
    }

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        View view = inflater.inflate(R.layout.fragment_conversation123_recording, container, false);

        scrollView = view.findViewById(R.id.scrollView);
        passageContainer = view.findViewById(R.id.passageContainer);
        statusText = view.findViewById(R.id.statusText);
        playButton = view.findViewById(R.id.micButton);
        pauseButton = view.findViewById(R.id.stopButton);
        speedSelector = view.findViewById(R.id.speedSelector);
        voiceSelectionButton = view.findViewById(R.id.voiceSelectionButton);
        downloadFab = view.findViewById(R.id.downloadFab);

        playButton.setEnabled(false);
        pauseButton.setVisibility(View.GONE);
        downloadFab.setVisibility(View.GONE);

        loadPassageDataFromFile();
        updateContent();

        playButton.setOnClickListener(v -> playAudio());
        pauseButton.setOnClickListener(v -> pauseAudio());

        downloadFab.setOnClickListener(v -> combineAndDownloadRecordings());

        voiceSelectionButton.setOnClickListener(v -> showVoiceSelectionDialog());

        ArrayAdapter<CharSequence> speedAdapter = ArrayAdapter.createFromResource(requireContext(),
                R.array.playback_speeds, android.R.layout.simple_spinner_item);
        speedAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
        speedSelector.setAdapter(speedAdapter);
        speedSelector.setSelection(2);

        speedSelector.setOnItemSelectedListener(new AdapterView.OnItemSelectedListener() {
            @Override
            public void onItemSelected(AdapterView<?> parent, View view, int position, long id) {
                float[] actualSpeeds = {0.75f, 1.0f, 1.10f, 1.25f, 1.50f, 2.0f};
                float selectedSpeed = actualSpeeds[position];
                if (tts != null) {
                    tts.setSpeechRate(selectedSpeed);
                }
            }

            @Override
            public void onNothingSelected(AdapterView<?> parent) {}
        });

        try {
            Context context = getContext();
            if (context != null) {
                IntentFilter filter = new IntentFilter(ConnectivityManager.CONNECTIVITY_ACTION);
                context.registerReceiver(networkChangeReceiver, filter);
            }
        } catch (Exception e) {
            Log.e("ConversationRecordingFragment", "Failed to register receiver", e);
        }

        return view;
    }

    private void showVoiceSelectionDialog() {
        Context context = getContext();
        if (context == null || !isAdded() || isFragmentDestroyed) return;

        if (tts != null && isSpeaking) {
            pauseAudio();
        }

        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setTitle("Select Voice");

        final String[] voiceOptions = getResources().getStringArray(R.array.voice_types);
        int selectedIndex = getCurrentLanguageIndex();

        builder.setSingleChoiceItems(voiceOptions, selectedIndex, (dialog, which) -> {
            String previousLanguage = currentLanguage;

            switch (which) {
                case 0:
                    currentLanguage = "US-English";
                    break;
                case 1:
                    currentLanguage = "UK-English";
                    break;
                case 2:
                    currentLanguage = "AUS-English";
                    break;
                case 3:
                    currentLanguage = "IN-English";
                    break;
            }

            if (!currentLanguage.equals(previousLanguage)) {
                Context ctx = getContext();
                if (ctx != null && isAdded() && !isFragmentDestroyed) {
                    Toast.makeText(ctx, "Voice changed to " + voiceOptions[which], Toast.LENGTH_SHORT).show();
                }

                if (tts != null) {
                    setLanguageForCurrentSelection();
                }
                resetAudio();
            }

            dialog.dismiss();
        });

        builder.setNegativeButton("Cancel", (dialog, which) -> {
            if (tts != null && !isSpeaking && shouldContinuePlayback) {
                playAudio();
            }
            dialog.dismiss();
        });

        builder.setOnDismissListener(dialog -> {
            if (tts != null && !isSpeaking && shouldContinuePlayback) {
                playAudio();
            }
        });

        builder.show();
    }

    private int getCurrentLanguageIndex() {
        switch (currentLanguage) {
            case "UK-English": return 1;
            case "AUS-English": return 2;
            case "IN-English": return 3;
            default: return 0;
        }
    }

    private void parseSentences(String text) {
        sentences.clear();
        recordingMicButtons.clear();
        recordingStopButtons.clear();
        passageContainer.removeAllViews();

        String[] lines = text.split("\n");
        int sentenceIndex = 0;

        for (String line : lines) {
            line = line.trim();
            if (line.isEmpty() || line.startsWith("#")) {
                continue;
            }

            boolean isPersonA = line.startsWith("Person A:");
            boolean isPersonB = line.startsWith("Person B:");

            if (isPersonA || isPersonB) {
                Sentence sentence = new Sentence(line, isPersonA, sentenceIndex);
                sentences.add(sentence);

                // Create UI for this sentence
                createSentenceUI(sentence);

                sentenceIndex++;
            }
        }

        currentSentenceIndex = 0;
    }

    private void createSentenceUI(Sentence sentence) {
        // Create a horizontal layout for buttons + sentence
        LinearLayout sentenceLayout = new LinearLayout(getContext());
        sentenceLayout.setOrientation(LinearLayout.HORIZONTAL);
        sentenceLayout.setLayoutParams(new LinearLayout.LayoutParams(
                LinearLayout.LayoutParams.MATCH_PARENT,
                LinearLayout.LayoutParams.WRAP_CONTENT
        ));
        sentenceLayout.setGravity(Gravity.CENTER_VERTICAL);
        sentenceLayout.setPadding(0, 12, 0, 12);

        // Create mic button
        ImageButton micButton = new ImageButton(getContext());
        micButton.setImageResource(R.drawable.ic_mic);
        micButton.setBackgroundResource(R.drawable.circular_button);
        micButton.setScaleType(ImageButton.ScaleType.CENTER_INSIDE);
        micButton.setPadding(6, 6, 6, 6);

        int buttonSize = 24;
        float density = getResources().getDisplayMetrics().density;
        int pixelSize = (int) (buttonSize * density);
        LinearLayout.LayoutParams buttonParams = new LinearLayout.LayoutParams(pixelSize, pixelSize);
        buttonParams.setMargins(0, 0, 8, 0);
        micButton.setLayoutParams(buttonParams);

        // Set color based on person
        if (sentence.isPersonA) {
            micButton.setColorFilter(colorPersonA);
        } else {
            micButton.setColorFilter(colorPersonB);
        }

        micButton.setTag(sentence.index);
        micButton.setOnClickListener(v -> {
            int index = (Integer) v.getTag();
            startRecordingForSentence(index);
        });

        // Create stop button
        ImageButton stopButton = new ImageButton(getContext());
        stopButton.setImageResource(R.drawable.ic_stop);
        stopButton.setBackgroundResource(R.drawable.circular_button);
        stopButton.setScaleType(ImageButton.ScaleType.CENTER_INSIDE);
        stopButton.setPadding(6, 6, 6, 6);
        stopButton.setVisibility(View.GONE);

        LinearLayout.LayoutParams stopButtonParams = new LinearLayout.LayoutParams(pixelSize, pixelSize);
        stopButtonParams.setMargins(0, 0, 8, 0);
        stopButton.setLayoutParams(stopButtonParams);

        stopButton.setTag(sentence.index);
        stopButton.setOnClickListener(v -> {
            int index = (Integer) v.getTag();
            stopRecordingForSentence(index);
        });

        // Create TextView for the sentence
        TextView sentenceTextView = new TextView(getContext());
        sentenceTextView.setText(sentence.text);
        sentenceTextView.setTextSize(16);
        sentenceTextView.setTypeface(null, Typeface.BOLD);
        sentenceTextView.setPadding(4, 16, 16, 16);
        sentenceTextView.setLayoutParams(new LinearLayout.LayoutParams(
                0,
                LinearLayout.LayoutParams.WRAP_CONTENT,
                1.0f
        ));

        // Color only "Person A:" or "Person B:" part
        SpannableString spannable = new SpannableString(sentence.text);
        int color = sentence.isPersonA ? colorPersonA : colorPersonB;
        spannable.setSpan(new ForegroundColorSpan(color),
                0, 9,
                Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

        sentenceTextView.setText(spannable);

        // Add views to the layout
        sentenceLayout.addView(micButton);
        sentenceLayout.addView(stopButton);
        sentenceLayout.addView(sentenceTextView);

        // Add the layout to the container
        passageContainer.addView(sentenceLayout);

        // Store references for later use
        recordingMicButtons.put(sentence.index, micButton);
        recordingStopButtons.put(sentence.index, stopButton);
        sentence.micButton = micButton;
        sentence.stopButton = stopButton;
        sentence.textView = sentenceTextView;
    }

    private void startRecordingForSentence(int index) {
        if (isRecording) {
            stopRecording();
        }

        currentSentenceIndex = index;
        highlightCurrentSentence();
        startRecording();
    }

    private void stopRecordingForSentence(int index) {
        if (isRecording && currentSentenceIndex == index) {
            stopRecording();
        }
    }

    private void updateRecordingButtons() {
        for (int i = 0; i < sentences.size(); i++) {
            ImageButton micButton = recordingMicButtons.get(i);
            ImageButton stopButton = recordingStopButtons.get(i);

            if (micButton != null && stopButton != null) {
                boolean hasRecording = recordingFiles.containsKey(i);

                // Show mic button if no recording exists, show stop button if recording in progress
                if (isRecording && currentSentenceIndex == i) {
                    micButton.setVisibility(View.GONE);
                    stopButton.setVisibility(View.VISIBLE);
                } else {
                    micButton.setVisibility(hasRecording ? View.GONE : View.VISIBLE);
                    stopButton.setVisibility(View.GONE);
                }

                // Set color based on person
                Sentence sentence = sentences.get(i);
                int color = sentence.isPersonA ? colorPersonA : colorPersonB;
                micButton.setColorFilter(color);
                stopButton.setColorFilter(color);

                // Ensure proper background
                if (i == currentSentenceIndex) {
                    micButton.setBackgroundColor(getHighlightColor());
                    stopButton.setBackgroundColor(getHighlightColor());
                } else {
                    micButton.setBackgroundResource(R.drawable.circular_button);
                    stopButton.setBackgroundResource(R.drawable.circular_button);
                }
            }
        }
    }

    private void highlightCurrentSentence() {
        if (sentences.isEmpty()) return;

        // Highlight the current sentence
        for (int i = 0; i < sentences.size(); i++) {
            Sentence sentence = sentences.get(i);
            if (sentence.textView != null) {
                if (i == currentSentenceIndex) {
                    // Create a new spannable with highlight
                    SpannableString spannable = new SpannableString(sentence.text);
                    int color = sentence.isPersonA ? colorPersonA : colorPersonB;

                    // Color only "Person A:" or "Person B:" part
                    spannable.setSpan(new ForegroundColorSpan(color),
                            0, 9,
                            Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

                    // Add highlight background to the whole text
                    spannable.setSpan(new BackgroundColorSpan(getHighlightColor()),
                            0, spannable.length(),
                            Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

                    sentence.textView.setText(spannable);

                    // Also highlight the buttons background
                    if (sentence.micButton != null) {
                        sentence.micButton.setBackgroundColor(getHighlightColor());
                    }
                    if (sentence.stopButton != null) {
                        sentence.stopButton.setBackgroundColor(getHighlightColor());
                    }
                } else {
                    // Remove highlight from other sentences
                    SpannableString spannable = new SpannableString(sentence.text);
                    int color = sentence.isPersonA ? colorPersonA : colorPersonB;

                    // Color only "Person A:" or "Person B:" part
                    spannable.setSpan(new ForegroundColorSpan(color),
                            0, 9,
                            Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

                    sentence.textView.setText(spannable);

                    // Remove highlight from buttons
                    if (sentence.micButton != null) {
                        sentence.micButton.setBackgroundResource(R.drawable.circular_button);
                    }
                    if (sentence.stopButton != null) {
                        sentence.stopButton.setBackgroundResource(R.drawable.circular_button);
                    }
                }
            }
        }

        scrollToCurrentSentence();
        updateRecordingButtons();
    }

    private void speakCurrentSentence() {
        if (tts == null || sentences.isEmpty() || currentSentenceIndex >= sentences.size()) {
            return;
        }

        Sentence sentence = sentences.get(currentSentenceIndex);
        Bundle params = new Bundle();
        params.putString(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, UTTERANCE_ID);

        setVoiceForPerson(sentence.isPersonA);
        tts.speak(sentence.cleanText, TextToSpeech.QUEUE_FLUSH, params, UTTERANCE_ID);
    }

    private void setVoiceForPerson(boolean isPersonA) {
        String maleBase = US_MALE;
        String femaleBase = US_FEMALE;

        switch (currentLanguage) {
            case "UK-English":
                maleBase = UK_MALE;
                femaleBase = UK_FEMALE;
                break;
            case "AUS-English":
                maleBase = AUS_MALE;
                femaleBase = AUS_FEMALE;
                break;
            case "IN-English":
                maleBase = IN_MALE;
                femaleBase = IN_FEMALE;
                break;
        }

        if (isPersonA) {
            if (!setVoice(maleBase + "-network")) {
                setVoice(maleBase + "-local");
            }
        } else {
            if (!setVoice(femaleBase + "-network")) {
                setVoice(femaleBase + "-local");
            }
        }
    }

    private void playAudio() {
        if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

        if (!voicesLoaded) {
            Context context = getContext();
            if (context != null) {
                Toast.makeText(context, "Voices are still loading, please wait...", Toast.LENGTH_SHORT).show();
            }
            return;
        }

        if (tts == null || passages.size() <= currentIndex || !voiceAvailable) {
            showErrorDialog("Unable to play audio");
            return;
        }

        shouldContinuePlayback = true;
        isLessonCompleted = false;
        highlightCurrentSentence();
        speakCurrentSentence();
    }

    private void pauseAudio() {
        if (tts != null && isSpeaking) {
            shouldContinuePlayback = false;
            tts.stop();
            isSpeaking = false;
            playButton.setVisibility(View.VISIBLE);
            pauseButton.setVisibility(View.GONE);
            setStatusText("Paused");
            stopRecording();
        }
    }

    private void resetAudio() {
        shouldContinuePlayback = false;
        isSpeaking = false;
        playButton.setVisibility(View.VISIBLE);
        pauseButton.setVisibility(View.GONE);
        currentSentenceIndex = 0;
        highlightCurrentSentence();
        setStatusText("Ready");
        stopRecording();
        stopAllRecordingsPlayback();
        updateRecordingButtons();
        isLessonCompleted = false;
        downloadFab.setVisibility(View.GONE);
    }

    private boolean setDefaultVoice() {
        if (tts.getDefaultVoice() != null) {
            return tts.setVoice(tts.getDefaultVoice()) == TextToSpeech.SUCCESS;
        }
        return false;
    }

    private boolean setVoice(String voiceName) {
        Set<Voice> voices = tts.getVoices();
        if (voices == null) return false;

        for (Voice voice : voices) {
            if (voice.getName().equals(voiceName)) {
                int result = tts.setVoice(voice);
                if (result == TextToSpeech.SUCCESS) {
                    Log.d("TTS", "Voice set successfully: " + voiceName);
                    return true;
                }
            }
        }
        Log.d("TTS", "Voice not available: " + voiceName);
        return false;
    }

    private void loadPassageDataFromFile() {
        InputStream inputStream = getResources().openRawResource(R.raw.conversation_passages);
        BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));
        StringBuilder contentBuilder = new StringBuilder();
        String line;
        try {
            String title = "";
            boolean isTitleFound = false;
            while ((line = reader.readLine()) != null) {
                if (line.trim().startsWith("#")) {
                    continue;
                }

                if (line.startsWith("Title:")) {
                    if (isTitleFound) {
                        passages.add(contentBuilder.toString().trim());
                        contentBuilder = new StringBuilder();
                    }
                    title = line.substring("Title:".length()).trim();
                    passageTitles.add(title);
                    isTitleFound = true;
                } else if (isTitleFound) {
                    contentBuilder.append(line).append("\n");
                }
            }
            if (isTitleFound) {
                passages.add(contentBuilder.toString().trim());
            }
            reader.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private void updateContent() {
        if (selectedTitle != null) {
            currentIndex = passageTitles.indexOf(selectedTitle);
            if (currentIndex >= 0 && currentIndex < passages.size()) {
                String passageText = passages.get(currentIndex);
                parseSentences(passageText);

                if (voicesLoaded && voiceAvailable) {
                    playButton.setEnabled(true);
                }
            }
        }
        resetAudio();
    }

    private int getHighlightColor() {
        int nightModeFlags = getResources().getConfiguration().uiMode & Configuration.UI_MODE_NIGHT_MASK;
        if (nightModeFlags == Configuration.UI_MODE_NIGHT_YES) {
            return Color.argb(255, 31, 58, 95);
        } else {
            return Color.YELLOW;
        }
    }

    // Recording methods
    private void startRecording() {
        if (isRecording) {
            stopRecording();
        }

        try {
            File storageDir = requireContext().getExternalFilesDir(Environment.DIRECTORY_MUSIC);
            if (storageDir != null && !storageDir.exists()) {
                storageDir.mkdirs();
            }

            String fileName = "recording_" + currentSentenceIndex + "_" + System.currentTimeMillis() + ".3gp";
            File recordingFile = new File(storageDir, fileName);

            mediaRecorder = new MediaRecorder();
            mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);
            mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
            mediaRecorder.setOutputFile(recordingFile.getAbsolutePath());
            mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB);

            mediaRecorder.prepare();
            mediaRecorder.start();
            isRecording = true;
            setStatusText("\uD83C\uDFA4 Recording...");
            startBlinking();

            // Update UI
            updateRecordingButtons();

        } catch (IOException e) {
            Log.e("Recording", "Failed to start recording", e);
            setStatusText("Recording failed");
        } catch (Exception e) {
            Log.e("Recording", "Unexpected error starting recording", e);
            setStatusText("Recording failed");
        }
    }

    private void stopRecording() {
        if (isRecording && mediaRecorder != null) {
            try {
                mediaRecorder.stop();
                mediaRecorder.release();

                // Save the recording file path
                File storageDir = requireContext().getExternalFilesDir(Environment.DIRECTORY_MUSIC);
                if (storageDir != null) {
                    // Find the latest recording file for this sentence
                    File[] files = storageDir.listFiles((dir, name) ->
                            name.startsWith("recording_" + currentSentenceIndex + "_") && name.endsWith(".3gp"));

                    if (files != null && files.length > 0) {
                        // Get the most recent file
                        File latestFile = files[0];
                        for (File file : files) {
                            if (file.lastModified() > latestFile.lastModified()) {
                                latestFile = file;
                            }
                        }
                        recordingFiles.put(currentSentenceIndex, latestFile.getAbsolutePath());

                        // Update UI to show recording is available
                        updateRecordingButtons();
                    }
                }

            } catch (Exception e) {
                Log.e("Recording", "Failed to stop recording", e);
                mediaRecorder.release();
            }
            mediaRecorder = null;
            isRecording = false;
            stopBlinking();
            setStatusText("Recording saved");
        }
    }

    private void startBlinking() {
        stopBlinking();

        blinkRunnable = new Runnable() {
            boolean isRed = false;

            @Override
            public void run() {
                if (!isRecording || !isAdded() || isFragmentDestroyed) return;

                ImageButton micButton = recordingMicButtons.get(currentSentenceIndex);
                if (micButton != null) {
                    if (isRed) {
                        micButton.setColorFilter(Color.RED);
                    } else {
                        int color = sentences.get(currentSentenceIndex).isPersonA ? colorPersonA : colorPersonB;
                        micButton.setColorFilter(color);
                    }
                    isRed = !isRed;
                }

                blinkHandler.postDelayed(this, 500);
            }
        };

        blinkHandler.post(blinkRunnable);
    }

    private void stopBlinking() {
        blinkHandler.removeCallbacks(blinkRunnable);
        blinkRunnable = null;

        // Reset mic button color
        if (currentSentenceIndex >= 0 && currentSentenceIndex < sentences.size()) {
            ImageButton micButton = recordingMicButtons.get(currentSentenceIndex);
            if (micButton != null) {
                int color = sentences.get(currentSentenceIndex).isPersonA ? colorPersonA : colorPersonB;
                micButton.setColorFilter(color);
            }
        }
    }

    private void playRecording(int index) {
        if (isPlayingRecording || isPlayingTTSForRecording) {
            pauseRecording(currentlyPlayingRecording);
            if (tts != null && isPlayingTTSForRecording) {
                tts.stop();
                isPlayingTTSForRecording = false;
            }
        }

        if (recordingFiles.containsKey(index)) {
            playTTSForRecording(index);
        } else {
            Toast.makeText(getContext(), "No recording available for this sentence", Toast.LENGTH_SHORT).show();
        }
    }

    private void playTTSForRecording(int index) {
        if (tts == null || index >= sentences.size()) return;

        Sentence sentence = sentences.get(index);
        currentlyPlayingRecording = index;

        setStatusText("Playing example...");

        Bundle params = new Bundle();
        params.putString(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, RECORDING_UTTERANCE_ID);

        setVoiceForPerson(sentence.isPersonA);
        tts.speak(sentence.cleanText, TextToSpeech.QUEUE_FLUSH, params, RECORDING_UTTERANCE_ID);
    }

    private void playUserRecording(int index) {
        if (recordingFiles.containsKey(index)) {
            String filePath = recordingFiles.get(index);

            try {
                MediaPlayer mediaPlayer = new MediaPlayer();
                mediaPlayer.setDataSource(filePath);
                mediaPlayer.prepare();

                mediaPlayer.setOnCompletionListener(mp -> {
                    stopRecordingPlayback(index);
                    updateRecordingButtons();
                });

                mediaPlayer.start();
                mediaPlayers.put(index, mediaPlayer);
                isPlayingRecording = true;
                currentlyPlayingRecording = index;

                setStatusText("Playing your recording...");

            } catch (IOException e) {
                Log.e("Recording", "Failed to play recording: " + e.getMessage());
                Toast.makeText(getContext(), "Failed to play recording: File not found", Toast.LENGTH_SHORT).show();

                recordingFiles.remove(index);
                updateRecordingButtons();
            } catch (Exception e) {
                Log.e("Recording", "Failed to play recording", e);
                Toast.makeText(getContext(), "Failed to play recording", Toast.LENGTH_SHORT).show();
            }
        }
    }

    private void pauseRecording(int index) {
        if (mediaPlayers.containsKey(index)) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            if (mediaPlayer.isPlaying()) {
                mediaPlayer.pause();
                isPlayingRecording = false;
                setStatusText("Paused");
            }
        }

        if (isPlayingTTSForRecording && tts != null) {
            tts.stop();
            isPlayingTTSForRecording = false;
            setStatusText("Paused");
        }
    }

    private void stopRecordingPlayback(int index) {
        if (mediaPlayers.containsKey(index)) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            mediaPlayer.release();
            mediaPlayers.remove(index);
            isPlayingRecording = false;
            currentlyPlayingRecording = -1;
            setStatusText("Ready");
        }
    }

    private void stopAllRecordingsPlayback() {
        for (int index : mediaPlayers.keySet()) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            mediaPlayer.release();
        }
        mediaPlayers.clear();
        isPlayingRecording = false;
        currentlyPlayingRecording = -1;

        if (isPlayingTTSForRecording && tts != null) {
            tts.stop();
            isPlayingTTSForRecording = false;
        }

        setStatusText("Ready");
    }

    private void combineAndDownloadRecordings() {
        if (recordingFiles.isEmpty()) {
            Toast.makeText(getContext(), "No recordings available to download", Toast.LENGTH_SHORT).show();
            return;
        }

        setStatusText("Combining recordings...");

        // This is a placeholder - you'll need to implement actual audio combining logic
        // using a library like Android's MediaMuxer or a third-party library

        Toast.makeText(getContext(), "Download feature coming soon!", Toast.LENGTH_SHORT).show();
        setStatusText("Ready");
    }

    private void showErrorDialog(String message) {
        Context context = getContext();
        if (context == null) return;

        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setTitle("Error");
        builder.setMessage(message);
        builder.setPositiveButton("OK", (dialog, which) -> dialog.dismiss());
        builder.show();
    }

    private void showVoiceNotAvailableToast() {
        Context context = getContext();
        if (context == null || !isAdded() || isFragmentDestroyed) return;

        Toast.makeText(context,
                "Preferred voice not available. Using default voice.",
                Toast.LENGTH_LONG).show();
    }

    private boolean isNetworkAvailable() {
        Context context = getContext();
        if (context == null || !isAdded() || isFragmentDestroyed) return false;

        ConnectivityManager connectivityManager = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);
        if (connectivityManager == null) return false;

        NetworkInfo activeNetworkInfo = connectivityManager.getActiveNetworkInfo();
        return activeNetworkInfo != null && activeNetworkInfo.isConnected();
    }

    private void showNoInternetDialog() {
        Context context = getContext();
        if (context == null) return;

        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setTitle("\uD83D\uDCF6 Internet Required");
        builder.setMessage("High-quality voices require internet. Connect to Wi-Fi or mobile data to use them.");

        builder.setPositiveButton("Retry", (dialog, which) -> {
            if (isNetworkAvailable()) {
                loadAvailableVoices();
            } else {
                showNoInternetDialog();
            }
        });

        builder.setNegativeButton("Cancel", (dialog, which) -> {
            Toast.makeText(context,
                    "Using default voice. High-quality voices require internet.",
                    Toast.LENGTH_LONG).show();
            dialog.dismiss();
        });

        builder.show();
    }

    @Override
    public void onDestroyView() {
        super.onDestroyView();
        isFragmentDestroyed = true;
        isFragmentVisible = false;

        handler.removeCallbacksAndMessages(null);
        blinkHandler.removeCallbacksAndMessages(null);

        if (tts != null) {
            tts.stop();
            tts.setOnUtteranceProgressListener(null);
            tts.shutdown();
        }

        stopRecording();
        stopAllRecordingsPlayback();

        try {
            Context context = getContext();
            if (context != null) {
                context.unregisterReceiver(networkChangeReceiver);
            }
        } catch (IllegalArgumentException e) {
            // Already unregistered or context is invalid
        }
    }
}
