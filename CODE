package com.spoka.english;

import android.app.Activity;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.content.res.Configuration;
import android.graphics.Color;
import android.graphics.Typeface;
import android.media.MediaPlayer;
import android.media.MediaRecorder;
import android.net.ConnectivityManager;
import android.net.NetworkInfo;
import android.os.Bundle;
import android.os.Environment;
import android.os.Handler;
import android.speech.tts.TextToSpeech;
import android.speech.tts.UtteranceProgressListener;
import android.speech.tts.Voice;
import android.text.Spannable;
import android.text.SpannableString;
import android.text.style.BackgroundColorSpan;
import android.text.style.ForegroundColorSpan;
import android.util.Log;
import android.view.Gravity;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.ImageButton;
import android.widget.LinearLayout;
import android.widget.ScrollView;
import android.widget.Spinner;
import android.widget.TextView;
import android.widget.ArrayAdapter;
import android.widget.AdapterView;
import android.app.AlertDialog;
import android.content.BroadcastReceiver;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Set;

public class ConversationRecordingFragment extends Fragment {

    private static final String ARG_SELECTED_TITLE = "selectedTitle";
    private static final String ARG_ACTIVITY_TYPE = "activityType";
    private static final String UTTERANCE_ID = "ttsUtterance";
    private static final String RECORDING_UTTERANCE_ID = "recordingTtsUtterance";

    private static final String US_MALE = "en-us-x-iom";
    private static final String US_FEMALE = "en-us-x-tpc";
    private static final String UK_MALE = "en-gb-x-gbb";
    private static final String UK_FEMALE = "en-gb-x-gba";
    private static final String AUS_MALE = "en-au-x-aub";
    private static final String AUS_FEMALE = "en-au-x-auc";
    private static final String IN_MALE = "en-in-x-ene";
    private static final String IN_FEMALE = "en-in-x-enc";

    private LinearLayout passageContainer;
    private TextView statusText;
    private ImageButton micButton, pauseButton, voiceSelectionButton;
    private Spinner speedSelector;
    private ScrollView scrollView;
    private TextToSpeech tts;
    private Handler handler = new Handler();
    private int currentIndex = 0;

    private List<String> passageTitles = new ArrayList<>();
    private List<String> passages = new ArrayList<>();
    private List<Sentence> sentences = new ArrayList<>();
    private int currentSentenceIndex = 0;
    private boolean shouldContinuePlayback = false;
    private boolean isSpeaking = false;
    private long lastUtteranceDuration = 0;
    private long sentenceStartTime = 0;
    private boolean isFragmentVisible = false;
    private boolean isFragmentDestroyed = false;
    private boolean isLessonComplete = false;

    private String selectedTitle;
    private String activityType;
    private String currentLanguage = "US-English";

    private boolean voiceAvailable = false;
    private boolean voicesLoaded = false;
    private boolean loadingVoices = false;

    private int colorPersonA;
    private int colorPersonB;

    // Recording variables
    private MediaRecorder mediaRecorder;
    private Map<Integer, String> recordingFiles = new HashMap<>();
    private Map<Integer, MediaPlayer> mediaPlayers = new HashMap<>();
    private Map<Integer, ImageButton> recordingPlayButtons = new HashMap<>();
    private int currentlyPlayingRecording = -1;
    private boolean isRecording = false;
    private boolean isPlayingRecording = false;
    private boolean isPlayingTTSForRecording = false;

    // Store state when user interrupts recording to play a specific sentence
    private boolean wasRecordingInterrupted = false;
    private int interruptedSentenceIndex = -1;

    private class Sentence {
        String text;
        boolean isPersonA;
        String cleanText;
        int index;
        TextView textView;
        ImageButton playButton;

        public Sentence(String text, boolean isPersonA, int index) {
            this.text = text;
            this.isPersonA = isPersonA;
            this.cleanText = text.replaceFirst("^Person [AB]:\\s*", "");
            this.index = index;
        }
    }

    private BroadcastReceiver networkChangeReceiver = new BroadcastReceiver() {
        @Override
        public void onReceive(Context context, Intent intent) {
            if (!isAdded() || isFragmentDestroyed) return;
            if (!isNetworkAvailable()) {
                showNoInternetDialog();
            }
        }
    };

    public static ConversationRecordingFragment newInstance(String selectedTitle, String activityType) {
        ConversationRecordingFragment fragment = new ConversationRecordingFragment();
        Bundle args = new Bundle();
        args.putString(ARG_SELECTED_TITLE, selectedTitle);
        args.putString(ARG_ACTIVITY_TYPE, activityType);
        fragment.setArguments(args);
        return fragment;
    }

    @Override
    public void onCreate(@Nullable Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        if (getArguments() != null) {
            selectedTitle = getArguments().getString(ARG_SELECTED_TITLE);
            activityType = getArguments().getString(ARG_ACTIVITY_TYPE);
            colorPersonA = Color.parseColor("#2196F3");
            colorPersonB = Color.parseColor("#4CAF50");
        }
        initializeTts();
    }

    // Add this method for automatic cleanup of old files
    private void cleanupOldRecordings() {
        Context context = getContext();
        if (context == null) return;

        try {
            File cacheDir = context.getCacheDir();
            File[] files = cacheDir.listFiles((dir, name) -> name.startsWith("temp_recording_"));
            if (files != null) {
                long now = System.currentTimeMillis();
                for (File file : files) {
                    // Delete files older than 24 hours
                    if (now - file.lastModified() > 24 * 3600000) {
                        file.delete();
                    }
                }
            }
        } catch (Exception e) {
            Log.e("Recording", "Cleanup failed", e);
        }
    }


    @Override
    public void onResume() {
        super.onResume();
        isFragmentVisible = true;
        resetAudio();
        cleanupOldRecordings();
    }

    @Override
    public void onPause() {
        super.onPause();
        isFragmentVisible = false;

        // Always reset when fragment is paused (switched away from)
        resetFragment();
    }

    @Override
    public void onHiddenChanged(boolean hidden) {
        super.onHiddenChanged(hidden);
        if (hidden) {
            // Fragment is being hidden/switched away from
            resetFragment();
        }
    }
    private void initializeTts() {
        if (tts != null || !isAdded() || getContext() == null || isFragmentDestroyed) return;

        tts = new TextToSpeech(getContext(), status -> {
            if (!isAdded() || getContext() == null || isFragmentDestroyed) {
                if (tts != null) {
                    tts.shutdown();
                }
                return;
            }

            if (status == TextToSpeech.SUCCESS) {
                setLanguageForCurrentSelection();

                tts.setOnUtteranceProgressListener(new UtteranceProgressListener() {
                    @Override
                    public void onStart(String utteranceId) {
                        handler.post(() -> {
                            if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                            if (!isFragmentVisible) {
                                if (tts != null) tts.stop();
                                return;
                            }

                            if (UTTERANCE_ID.equals(utteranceId)) {
                                // Normal TTS playback
                                isSpeaking = true;
                                sentenceStartTime = System.currentTimeMillis();
                                micButton.setVisibility(View.GONE);
                                pauseButton.setVisibility(View.VISIBLE);
                                setStatusText("\uD83D\uDD0A Listen Carefully...");
                                scrollToCurrentSentence();
                            } else if (RECORDING_UTTERANCE_ID.equals(utteranceId)) {
                                // TTS for recording playback
                                isPlayingTTSForRecording = true;
                                setStatusText("Playing example...");
                            }
                        });
                    }

                    @Override
                    public void onDone(String utteranceId) {
                        handler.post(() -> {
                            if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                            if (!isFragmentVisible) return;

                            if (UTTERANCE_ID.equals(utteranceId)) {
                                // Normal TTS playback done
                                lastUtteranceDuration = System.currentTimeMillis() - sentenceStartTime;

                                if (shouldContinuePlayback) {
                                    setStatusText("\uD83D\uDDE3\uFE0F Repeat what you heard...");

                                    // Start recording after TTS finishes
                                    startRecording();

                                    handler.postDelayed(() -> {
                                        if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                                        if (!isFragmentVisible) return;

                                        // Stop recording and prepare for next sentence
                                        stopRecording();

                                        if (shouldContinuePlayback) {
                                            if (currentSentenceIndex < sentences.size() - 1) {
                                                currentSentenceIndex++;
                                                highlightCurrentSentence();
                                                updateRecordingButtons();
                                                speakCurrentSentence();
                                            } else {
                                                // Lesson completed
                                                isLessonComplete = true;

                                                // Set refresh icon
                                                micButton.setImageResource(R.drawable.ic_refresh);
                                                micButton.setVisibility(View.VISIBLE);
                                                pauseButton.setVisibility(View.GONE);
                                                setStatusText("Lesson Complete! Check your recordings.");
                                                shouldContinuePlayback = false;
                                                isSpeaking = false;

                                                // Remove highlight from current sentence after lesson completion
                                                removeCurrentSentenceHighlight();
                                            }
                                        }
                                    }, lastUtteranceDuration);
                                } else {
                                    isSpeaking = false;
                                    micButton.setVisibility(View.VISIBLE);
                                    pauseButton.setVisibility(View.GONE);
                                    setStatusText("Ready");
                                }
                            } else if (RECORDING_UTTERANCE_ID.equals(utteranceId)) {
                                // TTS for recording playback done - now play user recording
                                isPlayingTTSForRecording = false;
                                playUserRecording(currentlyPlayingRecording);
                            }
                        });
                    }

                    @Override
                    public void onError(String utteranceId) {
                        handler.post(() -> {
                            if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

                            if (UTTERANCE_ID.equals(utteranceId)) {
                                isSpeaking = false;
                                micButton.setVisibility(View.VISIBLE);
                                pauseButton.setVisibility(View.GONE);
                                setStatusText("Error occurred");
                            } else if (RECORDING_UTTERANCE_ID.equals(utteranceId)) {
                                isPlayingTTSForRecording = false;
                                setStatusText("Error playing example");
                            }
                        });
                    }
                });

                loadAvailableVoices();
            } else {
                Log.e("TTS", "Initialization failed");
                showErrorDialog("Text-to-speech initialization failed");
            }
        }, "com.google.android.tts");
    }

    private void removeCurrentSentenceHighlight() {
        if (sentences.isEmpty() || currentSentenceIndex >= sentences.size()) return;

        // Remove highlight only from the current sentence
        Sentence sentence = sentences.get(currentSentenceIndex);
        if (sentence.textView != null) {
            // Remove highlight from text
            SpannableString spannable = new SpannableString(sentence.text);
            int color = sentence.isPersonA ? colorPersonA : colorPersonB;

            // Color only "Person A:" or "Person B:" part
            spannable.setSpan(new ForegroundColorSpan(color),
                    0, 9,
                    Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

            sentence.textView.setText(spannable);

            // Remove highlight from play button - set circular background instead of color
            if (sentence.playButton != null) {
                sentence.playButton.setBackgroundResource(R.drawable.circular_button);
            }
        }

        // Also update recording buttons to ensure proper display
        updateRecordingButtons();
    }

    private void setLanguageForCurrentSelection() {
        Locale locale = Locale.US;
        switch (currentLanguage) {
            case "UK-English":
                locale = Locale.UK;
                break;
            case "AUS-English":
                locale = new Locale("en", "AU");
                break;
            case "IN-English":
                locale = new Locale("en", "IN");
                break;
        }
        int result = tts.setLanguage(locale);
        if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
            Log.e("TTS", "Language not supported");
        }
    }

    private void scrollToCurrentSentence() {
        if (passageContainer == null || sentences.isEmpty() || currentSentenceIndex >= sentences.size()) {
            return;
        }

        // Get the current sentence view
        View sentenceView = passageContainer.getChildAt(currentSentenceIndex);
        if (sentenceView != null) {
            // Get the position relative to the scroll view
            int scrollViewHeight = scrollView.getHeight();
            int desiredY = sentenceView.getTop() - (scrollViewHeight / 3);

            // Make sure we don't scroll beyond the content
            int maxScroll = passageContainer.getHeight() - scrollViewHeight;
            desiredY = Math.max(0, Math.min(desiredY, maxScroll));

            scrollView.smoothScrollTo(0, desiredY);
        }
    }

    private void setStatusText(String text) {
        if (statusText != null) {
            statusText.setText(text);
        }
    }

    private void loadAvailableVoices() {
        // Get context and activity first for safety checks
        Context context = getContext();
        Activity activity = getActivity();

        if (loadingVoices || context == null || activity == null || activity.isFinishing() ||
                activity.isDestroyed() || !isAdded() || isFragmentDestroyed) {
            return;
        }

        loadingVoices = true;
        voiceAvailable = false;

        new Thread(() -> {
            int retries = 0;
            while (tts != null && tts.getVoices() == null && retries < 5 && !isFragmentDestroyed) {
                try {
                    Thread.sleep(200);
                    retries++;
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    loadingVoices = false;
                    return;
                }
            }

            // Get fresh context/activity references for UI thread
            Context uiContext = getContext();
            Activity uiActivity = getActivity();

            if (uiContext == null || uiActivity == null || uiActivity.isFinishing() ||
                    uiActivity.isDestroyed() || !isAdded() || isFragmentDestroyed) {
                loadingVoices = false;
                return;
            }

            uiActivity.runOnUiThread(() -> {
                // Final safety check in UI thread
                Context finalContext = getContext();
                Activity finalActivity = getActivity();

                if (finalContext == null || finalActivity == null || finalActivity.isFinishing() ||
                        finalActivity.isDestroyed() || !isAdded() || isFragmentDestroyed) {
                    loadingVoices = false;
                    return;
                }

                voiceAvailable = setDefaultVoice();
                voicesLoaded = true;
                loadingVoices = false;

                if (voiceAvailable) {
                    Log.d("TTS", "Voices loaded successfully");
                    if (passages.size() > currentIndex && micButton != null) {
                        micButton.setEnabled(true);
                    }
                } else {
                    Log.d("TTS", "No voices available");
                    // Safe toast - use the finalContext we already checked
                    Toast.makeText(finalContext,
                            "Preferred voice not available. Using default voice.",
                            Toast.LENGTH_LONG).show();

                    if (micButton != null) {
                        micButton.setEnabled(false);
                    }
                }
            });
        }).start();
    }

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        View view = inflater.inflate(R.layout.fragment_conversation123_recording, container, false);

        scrollView = view.findViewById(R.id.scrollView);
        passageContainer = view.findViewById(R.id.passageContainer);
        statusText = view.findViewById(R.id.statusText);
        micButton = view.findViewById(R.id.micButton);
        pauseButton = view.findViewById(R.id.pauseButton);
        speedSelector = view.findViewById(R.id.speedSelector);
        voiceSelectionButton = view.findViewById(R.id.voiceSelectionButton);

        micButton.setEnabled(false);
        pauseButton.setVisibility(View.GONE);

        loadPassageDataFromFile();
        updateContent();

        micButton.setOnClickListener(v -> {
            if (isLessonComplete) {
                // Reset the lesson
                resetLesson();
            } else {
                playAudio();
            }
        });
        pauseButton.setOnClickListener(v -> pauseAudio());

        voiceSelectionButton.setOnClickListener(v -> showVoiceSelectionDialog());

        Context context = getContext();
        if (context == null) {
            Log.e("TAG", "Context is null, cannot create speed adapter");
            return view;
        }

        ArrayAdapter<CharSequence> speedAdapter = ArrayAdapter.createFromResource(context,
                R.array.playback_speeds, android.R.layout.simple_spinner_item);
        speedAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
        speedSelector.setAdapter(speedAdapter);
        speedSelector.setSelection(2);

        speedSelector.setOnItemSelectedListener(new AdapterView.OnItemSelectedListener() {
            @Override
            public void onItemSelected(AdapterView<?> parent, View view, int position, long id) {
                float[] actualSpeeds = {0.75f, 1.0f, 1.10f, 1.25f, 1.50f, 2.0f};
                float selectedSpeed = actualSpeeds[position];
                if (tts != null) {
                    tts.setSpeechRate(selectedSpeed);
                }
            }

            @Override
            public void onNothingSelected(AdapterView<?> parent) {
            }
        });

        try {
            context = getContext();
            if (context != null) {
                IntentFilter filter = new IntentFilter(ConnectivityManager.CONNECTIVITY_ACTION);
                context.registerReceiver(networkChangeReceiver, filter);
            }
        } catch (Exception e) {
            Log.e("ConversationRecordingFragment", "Failed to register receiver", e);
        }

        return view;
    }

    private void resetOnAccentChange() {
        // Stop any ongoing playback
        if (tts != null && isSpeaking) {
            tts.stop();
        }

        // Stop recording if active
        stopRecording();

        // Stop all recording playback
        stopAllRecordingsPlayback();

        // Delete all recorded files
        deleteAllRecordings();

        // Reset all states
        shouldContinuePlayback = false;
        isSpeaking = false;
        isPlayingRecording = false;
        isPlayingTTSForRecording = false;
        wasRecordingInterrupted = false;
        isLessonComplete = false;

        // Reset to first sentence
        currentSentenceIndex = 0;

        // Clear all recording references
        recordingFiles.clear();
        mediaPlayers.clear();

        // Update UI
        micButton.setImageResource(R.drawable.ic_mic);
        micButton.setVisibility(View.VISIBLE);
        pauseButton.setVisibility(View.GONE);
        setStatusText("Voice changed. Ready to start.");

        // Re-highlight the current sentence and update buttons
        highlightCurrentSentence();
        updateRecordingButtons();
    }

    private void resetFragment() {
        // Stop any ongoing activities
        if (tts != null && isSpeaking) {
            tts.stop();
        }

        stopRecording();
        stopAllRecordingsPlayback();

        // Delete all recorded files
        deleteAllRecordings();

        // Reset states
        shouldContinuePlayback = false;
        isSpeaking = false;
        isPlayingRecording = false;
        isPlayingTTSForRecording = false;
        wasRecordingInterrupted = false;
        isLessonComplete = false;

        // Clear all recording references
        recordingFiles.clear();
        mediaPlayers.clear();

        // Update UI
        micButton.setImageResource(R.drawable.ic_mic);
        micButton.setVisibility(View.VISIBLE);
        pauseButton.setVisibility(View.GONE);
        setStatusText("Ready");

        // Update recording buttons to hide all play icons
        updateRecordingButtons();
    }

    private void deleteAllRecordings() {
        Context context = getContext();
        if (context == null) return;

        try {
            File cacheDir = context.getCacheDir();
            if (cacheDir != null && cacheDir.exists()) {
                File[] files = cacheDir.listFiles((dir, name) ->
                        name.startsWith("temp_recording_") && name.endsWith(".3gp"));

                if (files != null) {
                    for (File file : files) {
                        try {
                            if (file.exists()) {
                                file.delete();
                            }
                        } catch (SecurityException e) {
                            Log.e("Recording", "Permission denied to delete file", e);
                        }
                    }
                }
            }
        } catch (Exception e) {
            Log.e("Recording", "Failed to delete recordings", e);
        }
    }
    private void resetLesson() {
        isLessonComplete = false;

        // Delete all recordings when resetting lesson
        deleteAllRecordings();

        // Set mic icon
        micButton.setImageResource(R.drawable.ic_mic);
        micButton.setVisibility(View.VISIBLE);
        pauseButton.setVisibility(View.GONE);

        // Clear all recording references
        recordingFiles.clear();
        mediaPlayers.clear();

        resetAudio();

        // Highlight the first sentence again
        highlightCurrentSentence();

        // Update buttons to hide all play icons
        updateRecordingButtons();
    }

    private void showVoiceSelectionDialog() {
        Context context = getContext();
        if (context == null || !isAdded() || isFragmentDestroyed) return;

        if (tts != null && isSpeaking) {
            pauseAudio();
        }

        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setTitle("Select Voice");

        final String[] voiceOptions = getResources().getStringArray(R.array.voice_types);
        int selectedIndex = getCurrentLanguageIndex();

        builder.setSingleChoiceItems(voiceOptions, selectedIndex, (dialog, which) -> {
            String previousLanguage = currentLanguage;

            switch (which) {
                case 0:
                    currentLanguage = "US-English";
                    break;
                case 1:
                    currentLanguage = "UK-English";
                    break;
                case 2:
                    currentLanguage = "AUS-English";
                    break;
                case 3:
                    currentLanguage = "IN-English";
                    break;
            }

            if (!currentLanguage.equals(previousLanguage)) {
                Context ctx = getContext();
                if (ctx != null && isAdded() && !isFragmentDestroyed) {
                    Toast.makeText(ctx, "Voice changed to " + voiceOptions[which], Toast.LENGTH_SHORT).show();
                }

                if (tts != null) {
                    setLanguageForCurrentSelection();
                }
                // Completely reset the fragment when accent changes
                resetOnAccentChange();
            }

            dialog.dismiss();
        });

        builder.setNegativeButton("Cancel", (dialog, which) -> {
            if (tts != null && !isSpeaking && shouldContinuePlayback) {
                playAudio();
            }
            dialog.dismiss();
        });

        builder.setOnDismissListener(dialog -> {
            if (tts != null && !isSpeaking && shouldContinuePlayback) {
                playAudio();
            }
        });

        builder.show();
    }

    private int getCurrentLanguageIndex() {
        switch (currentLanguage) {
            case "UK-English": return 1;
            case "AUS-English": return 2;
            case "IN-English": return 3;
            default: return 0;
        }
    }

    private void parseSentences(String text) {
        sentences.clear();
        recordingPlayButtons.clear();
        passageContainer.removeAllViews();

        String[] lines = text.split("\n");
        int sentenceIndex = 0;

        for (String line : lines) {
            line = line.trim();
            if (line.isEmpty() || line.startsWith("#")) {
                continue;
            }

            boolean isPersonA = line.startsWith("Person A:");
            boolean isPersonB = line.startsWith("Person B:");

            if (isPersonA || isPersonB) {
                Sentence sentence = new Sentence(line, isPersonA, sentenceIndex);
                sentences.add(sentence);

                // Create UI for this sentence
                createSentenceUI(sentence);

                sentenceIndex++;
            }
        }

        currentSentenceIndex = 0;
    }

    private void createSentenceUI(Sentence sentence) {
        // Create a horizontal layout for play button + sentence
        LinearLayout sentenceLayout = new LinearLayout(getContext());
        sentenceLayout.setOrientation(LinearLayout.HORIZONTAL);
        sentenceLayout.setLayoutParams(new LinearLayout.LayoutParams(
                LinearLayout.LayoutParams.MATCH_PARENT,
                LinearLayout.LayoutParams.WRAP_CONTENT
        ));
        sentenceLayout.setGravity(Gravity.CENTER_VERTICAL);
        sentenceLayout.setPadding(0, 12, 0, 12);

        // Add shadow divider to the bottom of each sentence except the last one
        if (sentence.index < sentences.size() - 1) {
            if (android.os.Build.VERSION.SDK_INT < android.os.Build.VERSION_CODES.JELLY_BEAN) {
                sentenceLayout.setBackgroundDrawable(getResources().getDrawable(R.drawable.shadow_divider));
            } else {
                sentenceLayout.setBackground(getResources().getDrawable(R.drawable.shadow_divider));
            }
        }

        // Create play/pause button
        ImageButton playPauseButton = new ImageButton(getContext());
        playPauseButton.setImageResource(android.R.drawable.ic_media_play);
        playPauseButton.setBackgroundResource(R.drawable.circular_button);
        playPauseButton.setScaleType(ImageButton.ScaleType.CENTER_INSIDE);
        playPauseButton.setPadding(6, 6, 6, 6);

        // Set button size with proper margins
        int buttonSize = 30;
        float density = getResources().getDisplayMetrics().density;
        int pixelSize = (int) (buttonSize * density);
        LinearLayout.LayoutParams buttonParams = new LinearLayout.LayoutParams(pixelSize, pixelSize);
        buttonParams.setMargins(0, 0, 16, 0);
        playPauseButton.setLayoutParams(buttonParams);

        // Set color based on person
        if (sentence.isPersonA) {
            playPauseButton.setColorFilter(colorPersonA);
        } else {
            playPauseButton.setColorFilter(colorPersonB);
        }

        playPauseButton.setTag(sentence.index);
        playPauseButton.setOnClickListener(v -> {
            int index = (Integer) v.getTag();
            ImageButton button = (ImageButton) v;

            if (button.isSelected()) {
                // Currently playing, so pause
                pauseRecording(index);
                button.setSelected(false);
                button.setImageResource(android.R.drawable.ic_media_play);
            } else {
                // Currently paused, so play
                if (isPlayingRecording && currentlyPlayingRecording == index) {
                    // Resume playback
                    resumeRecording(index);
                } else {
                    // Start new playback
                    playRecording(index);
                }
                button.setSelected(true);
                button.setImageResource(android.R.drawable.ic_media_pause);
            }
        });

        // Initially hide the button
        playPauseButton.setVisibility(View.GONE);

        // Create TextView for the sentence
        TextView sentenceTextView = new TextView(getContext());
        sentenceTextView.setText(sentence.text);
        sentenceTextView.setTextSize(16);
        sentenceTextView.setTypeface(null, Typeface.BOLD);
        sentenceTextView.setPadding(4, 16, 16, 16);
        sentenceTextView.setLayoutParams(new LinearLayout.LayoutParams(
                0,
                LinearLayout.LayoutParams.WRAP_CONTENT,
                1.0f
        ));

        // Color only "Person A:" or "Person B:" part
        SpannableString spannable = new SpannableString(sentence.text);
        int color = sentence.isPersonA ? colorPersonA : colorPersonB;
        spannable.setSpan(new ForegroundColorSpan(color),
                0, 9,
                Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

        sentenceTextView.setText(spannable);

        // Add views to the layout
        sentenceLayout.addView(playPauseButton);
        sentenceLayout.addView(sentenceTextView);

        // Add the layout to the container
        passageContainer.addView(sentenceLayout);

        // Store references for later use
        recordingPlayButtons.put(sentence.index, playPauseButton);
        sentence.playButton = playPauseButton;
        sentence.textView = sentenceTextView;
    }

    private void resumeRecording(int index) {
        if (mediaPlayers.containsKey(index)) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            mediaPlayer.start();
            isPlayingRecording = true;
            currentlyPlayingRecording = index;

            // Update UI
            ImageButton button = recordingPlayButtons.get(index);
            if (button != null) {
                button.setSelected(true);
                button.setImageResource(android.R.drawable.ic_media_pause);
            }

            setStatusText("Playing your recording...");
        }
    }

    private void updatePlayButtonState(int index, boolean isPlaying) {
        ImageButton button = recordingPlayButtons.get(index);
        if (button != null) {
            button.setSelected(isPlaying);
            button.setImageResource(isPlaying ?
                    android.R.drawable.ic_media_pause :
                    android.R.drawable.ic_media_play);
        }
    }

    private void updateRecordingButtons() {
        for (int i = 0; i < sentences.size(); i++) {
            ImageButton playButton = recordingPlayButtons.get(i);

            if (playButton != null) {
                boolean hasRecording = recordingFiles.containsKey(i);
                playButton.setVisibility(hasRecording ? View.VISIBLE : View.GONE);

                // Set color based on person
                Sentence sentence = sentences.get(i);
                if (sentence.isPersonA) {
                    playButton.setColorFilter(colorPersonA);
                } else {
                    playButton.setColorFilter(colorPersonB);
                }

                boolean isCurrentlyPlaying = (isPlayingRecording && currentlyPlayingRecording == i);
                playButton.setSelected(isCurrentlyPlaying);
                playButton.setImageResource(isCurrentlyPlaying ?
                        android.R.drawable.ic_media_pause :
                        android.R.drawable.ic_media_play);

                if (i == currentSentenceIndex && !isLessonComplete) {
                    playButton.setBackgroundColor(getHighlightColor());
                } else {
                    playButton.setBackgroundResource(R.drawable.circular_button);
                }
            }
        }
    }

    private void highlightCurrentSentence() {
        if (sentences.isEmpty()) return;

        // Don't highlight if lesson is complete
        if (isLessonComplete) {
            removeCurrentSentenceHighlight();
            return;
        }

        // Highlight the current sentence
        for (int i = 0; i < sentences.size(); i++) {
            Sentence sentence = sentences.get(i);
            if (sentence.textView != null) {
                if (i == currentSentenceIndex) {
                    // Create a new spannable with highlight
                    SpannableString spannable = new SpannableString(sentence.text);
                    int color = sentence.isPersonA ? colorPersonA : colorPersonB;

                    // Color only "Person A:" or "Person B:" part
                    spannable.setSpan(new ForegroundColorSpan(color),
                            0, 9,
                            Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

                    // Add highlight background to the whole text
                    spannable.setSpan(new BackgroundColorSpan(getHighlightColor()),
                            0, spannable.length(),
                            Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

                    sentence.textView.setText(spannable);

                    // Also highlight the play button background
                    if (sentence.playButton != null) {
                        sentence.playButton.setBackgroundColor(getHighlightColor());
                    }
                } else {
                    // Remove highlight from other sentences
                    SpannableString spannable = new SpannableString(sentence.text);
                    int color = sentence.isPersonA ? colorPersonA : colorPersonB;

                    // Color only "Person A:" or "Person B:" part
                    spannable.setSpan(new ForegroundColorSpan(color),
                            0, 9,
                            Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);

                    sentence.textView.setText(spannable);

                    // Remove highlight from play button
                    if (sentence.playButton != null) {
                        sentence.playButton.setBackgroundResource(R.drawable.circular_button);
                    }
                }
            }
        }

        scrollToCurrentSentence();
        updateRecordingButtons();
    }

    private void speakCurrentSentence() {
        if (tts == null || sentences.isEmpty() || currentSentenceIndex >= sentences.size()) {
            return;
        }

        Sentence sentence = sentences.get(currentSentenceIndex);
        Bundle params = new Bundle();
        params.putString(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, UTTERANCE_ID);

        setVoiceForPerson(sentence.isPersonA);
        tts.speak(sentence.cleanText, TextToSpeech.QUEUE_FLUSH, params, UTTERANCE_ID);
    }

    private void setVoiceForPerson(boolean isPersonA) {
        String maleBase = US_MALE;
        String femaleBase = US_FEMALE;

        switch (currentLanguage) {
            case "UK-English":
                maleBase = UK_MALE;
                femaleBase = UK_FEMALE;
                break;
            case "AUS-English":
                maleBase = AUS_MALE;
                femaleBase = AUS_FEMALE;
                break;
            case "IN-English":
                maleBase = IN_MALE;
                femaleBase = IN_FEMALE;
                break;
        }

        if (isPersonA) {
            if (!setVoice(maleBase + "-network")) {
                setVoice(maleBase + "-local");
            }
        } else {
            if (!setVoice(femaleBase + "-network")) {
                setVoice(femaleBase + "-local");
            }
        }
    }

    private void playAudio() {
        if (!isAdded() || getContext() == null || isFragmentDestroyed) return;

        if (!voicesLoaded) {
            Context context = getContext();
            if (context != null) {
                Toast.makeText(context, "Voices are still loading, please wait...", Toast.LENGTH_SHORT).show();
            }
            return;
        }

        if (tts == null || passages.size() <= currentIndex || !voiceAvailable) {
            showErrorDialog("Unable to play audio");
            return;
        }

        shouldContinuePlayback = true;
        highlightCurrentSentence();
        speakCurrentSentence();
    }

    private void pauseAudio() {
        if (tts != null && isSpeaking) {
            shouldContinuePlayback = false;
            tts.stop();
            isSpeaking = false;
            micButton.setVisibility(View.VISIBLE);
            pauseButton.setVisibility(View.GONE);
            setStatusText("Paused");
            stopRecording();
        }
    }

    private void resetAudio() {
        shouldContinuePlayback = false;
        isSpeaking = false;
        micButton.setVisibility(View.VISIBLE);
        pauseButton.setVisibility(View.GONE);
        currentSentenceIndex = 0;
        highlightCurrentSentence();
        setStatusText("Ready");
        stopRecording();
        stopAllRecordingsPlayback();
        updateRecordingButtons();

        // Ensure lesson completion state is reset
        if (isLessonComplete) {
            isLessonComplete = false;
            micButton.setImageResource(R.drawable.ic_mic);
        }
    }

    private boolean setDefaultVoice() {
        if (tts.getDefaultVoice() != null) {
            return tts.setVoice(tts.getDefaultVoice()) == TextToSpeech.SUCCESS;
        }
        return false;
    }

    private boolean setVoice(String voiceName) {
        Set<Voice> voices = tts.getVoices();
        if (voices == null) return false;

        for (Voice voice : voices) {
            if (voice.getName().equals(voiceName)) {
                int result = tts.setVoice(voice);
                if (result == TextToSpeech.SUCCESS) {
                    Log.d("TTS", "Voice set successfully: " + voiceName);
                    return true;
                }
            }
        }
        Log.d("TTS", "Voice not available: " + voiceName);
        return false;
    }

    private void loadPassageDataFromFile() {
        InputStream inputStream = getResources().openRawResource(R.raw.conversation_passages);
        BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));
        StringBuilder contentBuilder = new StringBuilder();
        String line;
        try {
            String title = "";
            boolean isTitleFound = false;
            while ((line = reader.readLine()) != null) {
                if (line.trim().startsWith("#")) {
                    continue;
                }

                if (line.startsWith("Title:")) {
                    if (isTitleFound) {
                        passages.add(contentBuilder.toString().trim());
                        contentBuilder = new StringBuilder();
                    }
                    title = line.substring("Title:".length()).trim();
                    passageTitles.add(title);
                    isTitleFound = true;
                } else if (isTitleFound) {
                    contentBuilder.append(line).append("\n");
                }
            }
            if (isTitleFound) {
                passages.add(contentBuilder.toString().trim());
            }
            reader.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private void updateContent() {
        if (selectedTitle != null) {
            currentIndex = passageTitles.indexOf(selectedTitle);
            if (currentIndex >= 0 && currentIndex < passages.size()) {
                String passageText = passages.get(currentIndex);
                parseSentences(passageText);

                if (voicesLoaded && voiceAvailable) {
                    micButton.setEnabled(true);
                }
            }
        }
        resetAudio();
    }

    private int getHighlightColor() {
        int nightModeFlags = getResources().getConfiguration().uiMode & Configuration.UI_MODE_NIGHT_MASK;
        if (nightModeFlags == Configuration.UI_MODE_NIGHT_YES) {
            return Color.argb(255, 31, 58, 95); // Dark blue with good contrast
        } else {
            return Color.YELLOW; // Solid yellow for light mode
        }
    }

    // Recording methods
    private void startRecording() {
        if (isRecording) {
            stopRecording();
        }

        try {
            Context context = getContext();
            if (context == null) return;

            // Check available storage space first
            File cacheDir = context.getCacheDir();
            if (cacheDir != null) {
                long freeSpace = cacheDir.getFreeSpace();
                if (freeSpace < 10 * 1024 * 1024) { // 5MB minimum
                    setStatusText("Storage full - cannot record");
                    Toast.makeText(context, "Storage full. Please free up space.", Toast.LENGTH_LONG).show();
                    return;
                }
            }

            String fileName = "temp_recording_" + currentSentenceIndex + "_" + System.currentTimeMillis() + ".3gp";
            File recordingFile = new File(cacheDir, fileName);

            mediaRecorder = new MediaRecorder();
            mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);
            mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
            mediaRecorder.setOutputFile(recordingFile.getAbsolutePath());
            mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB);

            mediaRecorder.prepare();
            mediaRecorder.start();
            isRecording = true;
            setStatusText("\uD83C\uDFA4 Recording...");

        } catch (IOException e) {
            Log.e("Recording", "Failed to start recording", e);
            // Handle storage errors gracefully
            if (e.getMessage() != null && (e.getMessage().contains("ENOSPC") || e.getMessage().contains("No space"))) {
                setStatusText("Storage full - cannot record");
                Toast.makeText(getContext(), "Storage full. Please free up space.", Toast.LENGTH_LONG).show();
            } else {
                setStatusText("Recording failed");
            }
        } catch (Exception e) {
            Log.e("Recording", "Unexpected error starting recording", e);
            setStatusText("Recording failed");
        }
    }

    private void stopRecording() {
        if (isRecording && mediaRecorder != null) {
            try {
                mediaRecorder.stop();
                mediaRecorder.release();

                // Save the recording file path from cache directory
                Context context = getContext();
                if (context == null) return;

                File cacheDir = context.getCacheDir();
                if (cacheDir != null) {
                    // Find the latest recording file for this sentence
                    File[] files = cacheDir.listFiles((dir, name) ->
                            name.startsWith("temp_recording_" + currentSentenceIndex + "_") && name.endsWith(".3gp"));

                    if (files != null && files.length > 0) {
                        // Get the most recent file
                        File latestFile = files[0];
                        for (File file : files) {
                            if (file.lastModified() > latestFile.lastModified()) {
                                latestFile = file;
                            }
                        }
                        recordingFiles.put(currentSentenceIndex, latestFile.getAbsolutePath());

                        // Update UI to show recording is available
                        updateRecordingButtons();
                    }
                }

            } catch (Exception e) {
                Log.e("Recording", "Failed to stop recording", e);
                // Even if stopping fails, we need to reset the mediaRecorder
                mediaRecorder.release();
            }
            mediaRecorder = null;
            isRecording = false;
        }
    }

    private void playRecording(int index) {
        if (isPlayingRecording || isPlayingTTSForRecording) {
            pauseRecording(currentlyPlayingRecording);
            if (tts != null && isPlayingTTSForRecording) {
                tts.stop();
                isPlayingTTSForRecording = false;
            }
        }

        // If we're in the middle of a recording session, remember the state
        if (isRecording || shouldContinuePlayback) {
            wasRecordingInterrupted = true;
            interruptedSentenceIndex = currentSentenceIndex;
            stopRecording();
            shouldContinuePlayback = false;
        }

        if (recordingFiles.containsKey(index)) {
            // First play TTS for this sentence, then the user recording
            playTTSForRecording(index);
        } else {
            Toast.makeText(getContext(), "No recording available for this sentence", Toast.LENGTH_SHORT).show();
        }
    }

    private void playTTSForRecording(int index) {
        if (tts == null || index >= sentences.size()) return;

        Sentence sentence = sentences.get(index);
        currentlyPlayingRecording = index;

        setStatusText("Playing example...");

        // Speak the sentence using TTS
        Bundle params = new Bundle();
        params.putString(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, RECORDING_UTTERANCE_ID);

        setVoiceForPerson(sentence.isPersonA);
        tts.speak(sentence.cleanText, TextToSpeech.QUEUE_FLUSH, params, RECORDING_UTTERANCE_ID);
    }

    private void playUserRecording(int index) {
        if (recordingFiles.containsKey(index)) {
            String filePath = recordingFiles.get(index);
            File recordingFile = new File(filePath);


            // Check if file still exists in cache
            if (!recordingFile.exists()) {
                Toast.makeText(getContext(), "Recording not available", Toast.LENGTH_SHORT).show();
                recordingFiles.remove(index);
                updateRecordingButtons();
                return;
            }

            try {
                MediaPlayer mediaPlayer = new MediaPlayer();
                mediaPlayer.setDataSource(filePath);
                mediaPlayer.prepare();

                mediaPlayer.setOnCompletionListener(mp -> {
                    stopRecordingPlayback(index);
                    updateRecordingButtons();

                    // If recording was interrupted, resume from the same sentence
                    if (wasRecordingInterrupted) {
                        resumeFromInterruptedRecording();
                    }
                });

                mediaPlayer.start();
                mediaPlayers.put(index, mediaPlayer);
                isPlayingRecording = true;
                currentlyPlayingRecording = index;

                // Update UI
                updatePlayButtonState(index, true);
                setStatusText("Playing your recording...");

            } catch (IOException e) {
                Log.e("Recording", "Failed to play recording: " + e.getMessage());
                Toast.makeText(getContext(), "Recording file not found", Toast.LENGTH_SHORT).show();
                recordingFiles.remove(index);
                updateRecordingButtons();
            } catch (Exception e) {
                Log.e("Recording", "Failed to play recording", e);
                Toast.makeText(getContext(), "Failed to play recording", Toast.LENGTH_SHORT).show();
            }
        } else {
            Toast.makeText(getContext(), "No recording available", Toast.LENGTH_SHORT).show();
        }
    }

    private void resumeFromInterruptedRecording() {
        wasRecordingInterrupted = false;
        currentSentenceIndex = interruptedSentenceIndex;
        interruptedSentenceIndex = -1;

        highlightCurrentSentence();
        updateRecordingButtons();

        // Continue with the lesson
        shouldContinuePlayback = true;
        speakCurrentSentence();
    }

    private void pauseRecording(int index) {
        if (mediaPlayers.containsKey(index)) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            if (mediaPlayer.isPlaying()) {
                mediaPlayer.pause();
                isPlayingRecording = false;

                // Update UI
                updatePlayButtonState(index, false);
                setStatusText("Paused");
            }
        }

        if (isPlayingTTSForRecording && tts != null) {
            tts.stop();
            isPlayingTTSForRecording = false;
            setStatusText("Paused");
        }
    }

    private void stopRecordingPlayback(int index) {
        if (mediaPlayers.containsKey(index)) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            mediaPlayer.release();
            mediaPlayers.remove(index);
            isPlayingRecording = false;
            currentlyPlayingRecording = -1;

            // Update UI
            updatePlayButtonState(index, false);
            setStatusText("Ready");
        }
    }

    private void stopAllRecordingsPlayback() {
        for (int index : mediaPlayers.keySet()) {
            MediaPlayer mediaPlayer = mediaPlayers.get(index);
            mediaPlayer.release();

            // Update UI
            updatePlayButtonState(index, false);
        }
        mediaPlayers.clear();
        isPlayingRecording = false;
        currentlyPlayingRecording = -1;

        if (isPlayingTTSForRecording && tts != null) {
            tts.stop();
            isPlayingTTSForRecording = false;
        }

        setStatusText("Ready");
    }

    private void showErrorDialog(String message) {
        Context context = getContext();
        if (context == null) return;

        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setTitle("Error");
        builder.setMessage(message);
        builder.setPositiveButton("OK", (dialog, which) -> dialog.dismiss());
        builder.show();
    }

    private void showVoiceNotAvailableToast() {
        Context context = getContext();
        if (context == null || !isAdded() || isFragmentDestroyed) return;

        Toast.makeText(context,
                "Preferred voice not available. Using default voice.",
                Toast.LENGTH_LONG).show();
    }

    private boolean isNetworkAvailable() {
        Context context = getContext();
        if (context == null || !isAdded() || isFragmentDestroyed) return false;

        ConnectivityManager connectivityManager = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);
        if (connectivityManager == null) return false;

        NetworkInfo activeNetworkInfo = connectivityManager.getActiveNetworkInfo();
        return activeNetworkInfo != null && activeNetworkInfo.isConnected();
    }

    private void showNoInternetDialog() {
        Context context = getContext();
        if (context == null) return;

        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setTitle("\uD83D\uDCF6 Internet Required");
        builder.setMessage("High-quality voices require internet. Connect to Wi-Fi or mobile data to use them.");

        builder.setPositiveButton("Retry", (dialog, which) -> {
            if (isNetworkAvailable()) {
                loadAvailableVoices();
            } else {
                showNoInternetDialog();
            }
        });

        builder.setNegativeButton("Cancel", (dialog, which) -> {
            Toast.makeText(context,
                    "Using default voice. High-quality voices require internet.",
                    Toast.LENGTH_LONG).show();
            dialog.dismiss();
        });

        builder.show();
    }

    @Override
    public void onDestroyView() {
        super.onDestroyView();
        isFragmentDestroyed = true;
        isFragmentVisible = false;

        handler.removeCallbacksAndMessages(null);

        if (tts != null) {
            tts.stop();
            tts.setOnUtteranceProgressListener(null);
            tts.shutdown();
        }

        stopRecording();
        stopAllRecordingsPlayback();

        try {
            Context context = getContext();
            if (context != null) {
                context.unregisterReceiver(networkChangeReceiver);
            }
        } catch (IllegalArgumentException e) {
            // Already unregistered or context is invalid
        }
    }
}
